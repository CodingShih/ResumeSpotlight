文獻  [20]中則近一步的說明 XAI 應該要具有的要素:可理解性,能讓
人理解模型是如何工作的而無須解釋內部的演算法方式，並且能為人類
所理解。透明性:整個模型必須能夠透明到讓人類能夠理解。 
文獻  [21]在論文中提到了 XAI 面臨到的各種挑戰，包括他們是否
需要考慮用戶缺乏的知識，並且如何提供反饋以及指導跟學習?以及是
否 AI 本身有盲點? 
文獻  [22]在他們的論文當中發展了命名為 Doctor AI 的多標籤分類
器，它會預測患者下次的就診時間，以及他們的診斷內容還有藥單。 
文獻  [23]  中不僅使用 LSTM 跟以及新聞頭條標題來預測預測股
價，並且透過 XAI 的工具 LIME(Local Interpretable Model-Agnostic 
Explanations)來解釋其結果。 
文獻  [24]中介紹了他們開發的 XAI 系統 Anchors,  能夠解釋 LSTM
情感分析的結果，並且分析 LSTM 是根據哪幾個詞的偏向來決定整體情
感預測的結果。除此之外也能處理機器翻譯在翻譯中的對應關係。 
文獻  [25]在他們的論文中介紹了情感分析的各種進展，並且介紹了
情緒分析的目標在於找到分析文本中的情感，並且對於其極性(polarity)
進行分類。 
文獻  [26]在他們的論文中談論到了關於人物、產品的情感分析，以
及分析情感分析的難度並且舉 twitter 的文本作為例子。文獻  [27]透過分
析 twitter 上面的資料來推斷評論對於三星股價的影響，正面、負面、以
及中性推文的演算法取得一定的成就。 
7 
2.2  相關技術探討 
循環神經網路(Recurrent Neural Network, RNN)，常被用在於時間序
列相關或是理解上下文的問題。所謂時間序列就是跟時間順序有關的問
題，也就是說當下的結果會受到過去的問題影響，而未來的結果也會受
到當下的結果影響，如此循環，因此它很適合用在處理跟時間有關係的
問題，像是金融方面等等。 
長短期記憶(Long Short-Term Memory，LSTM)，它也是時間循環神
經網路的一種，跟 RNN 不同的是它有一個單元可以記憶不同時間、不
同長度的數值。隨者訓練的層數或是時間的增加，神經網路很容易處現
梯度下降或是爆炸的問題。對於有順序的時間相關預測來說，LSTM 就
是為了能夠解決這個問題而誕生的。 
它由四個部分組成: Input Gate、Output Gate、Memory Cell 以及
Forget Gate。 
Input Gate:決定演算法是否將此次的值輸入並且運算。 
Output Gate:決定此次計算的值是否要輸出，沒有的話設為 0。 
Memory Cell:  控制此次計算的值是否要 output。 
Forget Gate:  控制是否將記憶清掉。 
可解釋人工智慧(Explainable AI，  XAI)  指的是能夠讓人們能夠理
解人工智慧的成果的技術。會需要使用這項技術是因為在實作人工智慧
的時候，它往往像是黑盒子一般，我們明白輸入到裡面的參數以及最後
的結果是正確的，卻因為黑盒子裡面的機制過於複雜導致人類難以追蹤
理解。為了能夠讓人能夠相信計算後的結果，於是有了 XAI 的概念
SHAP (SHAPley Additive exPlanations)  文獻  [28]說明 SHAP 是一種博奕
論在使用的方法，也就是 XAI 的實作方式。目的是為了能夠解釋機器學
習模型的內容。 
8 
它使用 SHAP 值來達成這個目標。SHAP 值就是想要衡量個別的特
徵對於整個模型它的貢獻程度，同時去除其他特徵的影響。公式如下: 
|𝐵|! (|𝐶| − |𝐵| − 1)!
|𝐶|!
𝐴𝑖 = ∑
𝐵⊆𝐶∖{𝑖}
[𝐹𝑏∪{𝑖}(𝐷𝑏∪{𝑖}) − 𝐹𝑏(𝐷𝑏)]
𝐴𝑖:  第 i 個 SHAP 值 
B:重新訓練的模型上用到的特徵子集 
C:全部特徵的特徵集 
𝐹𝑏∪{𝑖}:不使用使用第 i 個特徵訓練的模型 
𝐷𝑏:表示在集合 S 中輸入特徵 
  snownlp: snownlp 文獻  [29]是一個使用 Python 寫成的程式庫，他
的作用是可以很迅速且方便的處理中文字寫成的文章。主要的功用可以
把一句或是一段的文章透過內部的資料庫轉換成以條件機率表達的情感
數值。本論文使用其對於情感分析的功能來替我們準備好的新聞分析出
他的情感傾向是偏正面還是偏負面。情感分析使用數值來作表現，它的
範圍會在-1 跟 1 之間，-1 代表的是完全負面的情緒，1 代表的是完全正
面的情緒。而值得注意的是，因為原始的 snownlp 在訓練模型的時候使
用的是商品評論來做為訓練的資料。這樣子的模型對於本論文上需要分
析金融相關的新聞上可能會有預測情緒的偏差，為了解決這個問題，本
論文使用了中文金融情感词典來做為詞句的補充，從而盡量避免了前述
提到的問題。 
9 
三.  本文方法 
3.1  系統架構 
本論文首先從 TEJ+台灣經濟新報的資料庫中匯出新聞，這麼做是
考慮到新聞隨著時間過去，在網路上會有缺失難找的問題。當我們從
TEJ+台灣經濟新報的資料庫取出資料後，就可以把他轉換成 csv 檔。透
過 Python 就可對其進行資料預處理。當我們可以透過 Python 處理新聞
後，就能夠丟入 snownlp 的套件去進一步分析情緒。原始 snownlp 使用
的是商品評論做為資料集，為了更進一步的提高預測情感的準確，這邊
使用了中文金融情感詞典到 snownlp 的資料庫當中。 
透過 snownlp 訓練後，我們可以把新聞的文字轉換成 LSTM 可以看
得懂的數字做為特徵。這麼一來我們就可以去比較說有加入情感指數的
LSTM 預測模型跟沒有加入情感指數，單單是只有加權股價報酬指數本
身作為訓練集的 LSTM 模型究竟何者較好?最後結果會顯示出四種選定
的產業新聞加上 LSTM 預測跟原本 LSTM(訓練:2011/01/03~2018/12/22
驗證:2018/12/24~2019/12/27  測試:2019/12/30~2020/12/31)預測的結果做
比較，看會不會比較接近實際上的加權股價指數結果，並且加入了他人
論文的 LSTM 作為參考，看本論文提出的 LSTM 架構預測能力有沒有優
勢。 
最後為了調整模型讓模型有更好的結果，論文使用可解釋 AI (XAI)
的相關工具 SHAP 套件來可視化結果。透過 SHAP 可以了解到特徵對於
模型預測的影響。因此本論文進一步比較了情感指數的 LSTM 的 SHAP
值跟沒有加入情感指數的 LSTM 的 SHAP 值，來了解情感指數對於預測
是否有正向的影響。 
10 
3.2  資料收集 
本論文從 TEJ+經濟日報資料庫收集目標類型的個股的相關新聞文
章，在選擇產業新聞的議題上，因為每種新聞都有人研究，為了能夠更
大程度的包含所有投資人可能有興趣的新聞，同時也為了能夠讓訓練結
果更接近真實的資料，本研究參考台灣 50 組成的個股類型選擇出了鋼
鐵工業(M2000)、橡膠工業(M2100)、電子工業(M2300)、金融工業
(M2800)。 
TEJ+經濟日報資料庫裡面的資料來源來自於工商時報、經濟日報、
電子時報、財訊快報及精業嘉實新聞。搜集範圍包含跟該個產業相關的
新聞。這麼做的目的是為了能夠方便取得以往的資料，特別是因為時間
關係，過往的新聞很容易掩埋在搜尋引擎當中，導致分析不容易。 
最後是隨著各家網路新聞網頁數量的增加，以及社交媒體在網路上
的訊息不斷的增長，真正有用的訊息也是真假難辨，在後續的分析當中
也有可能包含人工操控的部分(比方說網軍或是公司故意為了抬高股價放
出假新聞)  ，更加導致無法反映出真實投資人對於股價市場的影響。因
此本論文才採取使用新聞資料庫的方式作為新聞資料方面的來源。 
11 
3.3  資料預處理 
我們可以把 TEJ+經濟日報資料庫裡面的資料匯出成 csv 檔案，並且
讓 Python  可以去讀取並且做後續的操作。 
表1.  M2000  鋼鐵工業相關新聞(節錄) 
comments 
＊豐興鋼筋每噸再漲 300  元，農曆年前有挑戰去年高點
實力今年入冬以來全球天氣極端變化，北半球的美國及歐洲
先前均受暴風雪襲擊，造成廢鐵收集運輸均不易(節錄) 
表2.  M2100  橡膠工業相關新聞(節錄) 
comments 
＊重建商機    五族群大補    石化、鋼鐵、水泥、輪胎、
生醫，訂單可望增加日本強震牽動原物料行情變化，帶動災
後重建商機，五大產業可望受惠。  (節錄) 
表3.  電子工業(M2300)相關新聞(節錄) 
comments 
＊顧能上調今年全球 IT 總支出至 3.6  兆美元，年增率
5.6%國際研調機構顧能(Gartner)  在最新預測中上調今年全球
IT 總支出至 3.6  兆美元  (節錄) 
表4.  金融業(M2800)相關新聞(節錄) 
date 
2011/1/3 
date 
2011/3/16 
date 
2011/3/31 
comments 
date 
＊合庫人壽將現增 20 億合作金庫銀行與法國巴黎人壽合
2011/1/6 
組的合庫人壽，因業務快速成長，被金管會要求增資  (節錄) 
12 
3.4  使用 snownlp 訓練 
讀取到資料庫裡的資料後就可以開始使用 snownlp 的套件。他是一
種可以處理自然語言的 Python  庫，有很多可以處理文字相關的操作，
本論文主要是透過其情緒處理的功能來分辨我們先前給予的新聞，並且
能夠透過已給定好的正向資料庫以及負向資料庫內的資料把句子或是詞
句分成正向以及負向。snownlp 的主要原理是透過單純貝氏分類器(Navie 
Bayes Classifer )並且運用條件機率的方式來把句子分類。他裡面已經有
現成的正向庫負向庫，裡面已經有分好正向跟負向的詞彙如果現在加入
新的文句的話，便會依照舊有的條件機率跟貝式定理，從而計算出新的
條件機率，因此本文提到的情感指數都是指透過 snownlp 計算出來的條
件機率。 
3.5  使用中文情感字典 
原始的 snownlp 的正向資料庫以及負向資料庫當中的資料是使用商
品評論的資料庫做為內部訓練的資料，在一般的情況下或許夠用，但是
如果面對金融相關的新聞的話，可能會有無法辨識的問題，因此為了能
夠增加 snownlp 對於金融方面的認識，我採用了中文金融情感词典所提
供的詞句，總共 9228 個詞句，負向 5890 個詞，正向 3338 個詞。  [30] 
[31] 
3.6  特徵擷取預測投資者情緒 
本論文透過 shownlp  我們可以把情感指數的值以及相關日期。 
表格從左到右分別顯示了新聞發生的日期、加權股價報酬指數的價
格’、以及最後透過 snownlp 計算出來的情感指數。如表 5 顯示了鋼鐵工
業相關新聞轉換的情感指數，表 6 顯示了和橡膠工業相關的新聞轉換的
情感指數，表 7 電子工業相關新聞轉換的情感指數，表 8 顯示了金融業
相關新聞轉換的情感指數。 
13 
表5.  M2000  鋼鐵工業相關新聞轉換之情感指數(節錄) 
Date 
2011/1/3 
2011/1/4 
price 
11998.76 
11961.39 
sentiment 
0 
0 
表6.  M2100  橡膠工業相關新聞轉換之情感指數(節錄) 
Date 
2011/1/3 
2011/1/4 
price 
11998.76 
11961.39 
sentiment 
0 
0 
表7.  M2300 電子工業相關新聞轉換之情感指數(節錄) 
Date 
2011/1/3 
2011/1/4 
price 
11998.76 
11961.39 
sentiment 
0 
0 
表8.  M2800 金融業相關新聞轉換之情感指數(節錄) 
Date 
2011/1/3 
2011/1/4 
price 
11998.76 
11961.39 
sentiment 
0 
0 
14 
3.7  LSTM 相關架構 
LSTM 內部有許多的參數可以供我們去做設定，主要需要更動的部
分是如表 9 的標題所示，分別為 LSTM Units, Dense, Optimizer, Dropout, 
Activation 等。本論文採用兩層 LSTM 的層數，LSTM Units 分別用/做為
區別。在參考其他論文多採取 2 的次方數作為 LSTM Units,  在其他實驗
當中本文作者也實驗過多層的或是奇數個 LSTM Units，但最終效果都沒
有比得上下方表 9 效果來的好，因此本論文最終採取了以下四種 LSTM 
Units 層數，分別為 50 / 50 , 256 /128, 128 /64, 64 /32 作為實驗結果。
Dense 以及 Optimizer 分別設置為 1 以及 Adam 同樣是因為在經歷過測試
後這是較好的組合，Dropout 設置成 0.2 是他每回合都會替換 20 百分比
的神經元，讓程式不會過度擬合  Activation  使用 relu 則是因為最終預測
結果不會落在負數(因為預測的是加權股價報酬指數，只有正整數)。 
表9. 
LSTM  相關參數 
LSTM Units 
Dense 
Optimizer  Dropout  Activation 
50 / 50 
256 /128 
128 /64 
64 /32 
1 
1 
1 
1 
Adam 
Adam 
Adam 
Adam 
0.2 
0.2 
0.2 
0.2 
relu 
relu 
relu 
relu 
模型的訓練次數總共都跑 1000 次，設定如果 80 次內模型沒有增長
就停止訓練，batch_size 設定為 128。此實驗是用來尋找 LSTM 較好的
神經元參數，一旦找到較好的參數之後，便拿他與加入情感指數作為新
的特徵的模型去做比較，來看哪邊預測效果較好。 
15 
3.8  XAI 解釋結果 
XAI 究竟是如何解釋結果的?  目前的論文對於 XAI 多是提到一些相
關的概念，比方說 XAI 的設計應該要有能夠正確的反應模型預測的原
因，且跟原模型是分離不相干，可以獨自評估模型好壞的。在實際落地
方面本論文採取了 SHAP  作為 XAI 的實際運用。SHAP 他能夠顯示每一
個特徵的貢獻度，因此我們可以看到說我們給予模型的每筆特徵(以本論
文來說就是加權股價報酬指數本身)  對於未來預測結果的貢獻。有了情
感指數做為新的特徵加入模型之後，新的特徵對於模型的預測結果也是
會有所影響的。因此我們就能透過 SHAP 值的變化得知加入新聞的情感
指數是否會對於預測有正面或是負面的影響。 
3.9  透過 MSE, RSME,r2-score 評估模型精準度 
最後就是模型的精準度部分。透過模型預測完結果之後，我們會得
到加權股價報酬的實際走勢以及預測的加權股價報酬指數的結果。如果
比較兩者只透過肉眼的話，會稍嫌不夠準確，因此本論文採取了機器學
習評估模型的方法 MSE, RSME,r2-score 來評估模型。 
16 
圖1.  實驗流程圖 
17 
四.  實驗結果與分析 
4.1  實驗環境與資料來源 
本論文使用的實驗環境如表 10，主要使用 Python  作為主要開發語
言，為了使用 LSTM 採用了 Tensorflow, Keras。在情感分析方面使用了
Python 的套件 snownlp，XAI 的部分則是使用了 SHAP,  相關使用方法都
來源於各個套件的 Github。 
表10.  實驗環境 
處理器 
AMD Ryzen 7 3800X 8-Core 
記憶體 
系統類型 
顯卡 
作業系統 
Python 
Keras 
Pandas 
Tensorflow 
SHAP 
Spyder 
Numpy 
Jupyter Notebook 
Matplotlib 
Sklearn 
snownlp 
Processor 3.90 GHz 
32GB 
64  位元作業系統，x64  型處理器 
NVIDIA GeForce GTX 1050Ti 
Windows 10  企業版 
版本: 3.6   
版本: 2.3.1 
版本: 1.1.5 
版本: 2.1.0 
版本: 0.39.0 
版本: 5.0.5 
版本: 1.19.5 
版本: 6.4.3 
版本: 3.3.4 
版本: 0.0 
版本: 0.12.3 
18 
4.2  評估模型精準度 
如同前面所提到為了能夠了解模型的精準度，本論文分別使用了
MSE, RMSE, r2-score 作為評估的手段，本論文將會於實驗當中運用這些
公式，並且將他們的實際結果繪製成圖做為實驗結果。下方公式是每個
公式的說明。 
均方差  Mean square error (MSE)  是很常見到的回歸損失函數，用來
評估預測的模型有沒有偏離現實太多。他的計算方法是求預測值跟真實
值之間距離的平方和，公式如下: 
MSE = 1
N
∑ (yi − ŷi)2
N
i=1
公式(1) 
RMSE 則是將 MSE 取平方，完整的 RMSE 公式如下: 
RMSE = √
1
m
∑ (yi − ŷi)2
m
i=1
公式(2) 
r2-score 透過跟第三者參照來比較模型，將預測與真實資訊取平方
以及取和，具體的公式如下: 
R2 = 1 −
∑ (yi − ŷi)2
∑ (yi − y2)2
n
i=1
n
i=1
公式(3) 
MSE, RSME, r2-score 他會比較預測值跟真實值的比例，越接近的
MSE, RSME 會越接近 0，r2-score 的分數則是會越接近 1，這代表預測
的加權股價報酬指數跟真實的加權股價報酬指數越接近。 
19 
4.3  實驗結果 
本論文每次的實驗總共會產生三張圖:  第一張 LSTM 神經網路之訓
練集損失值以及測試集損失值，這代表了每次 LSTM 在訓練的過程中透
過我們給定好的訓練集，他在訓練後會拿去跟測試集還有驗證集去做比
較，理想狀態是呈現下滑的曲線，這樣說明不管是在測試集上還是在驗
證集上訓練出來的模型效果都比較好。第二張說明了使用 MSE, RMSE, 
r2-score 對於模型的結果。第三張則是實際上加權股價報酬指數在測試
的時間段(2019/12/30~2020/12/31)以及預測的加權股價報酬指數結果。依
表 4 所示本論文的實驗結果分別如下: 
實驗一、LSTM Units 使用兩層，一層 50 個神經元、一層 50 個神經
元於第 111 回訓練時提前終止。 
圖2.   實驗一 LSTM 神經網絡之驗證集損失值以及測試集
損失值 
圖 2.X 軸為實驗一跑的回數，Y 軸為 loss 值，分別顯示了驗證集跟
測試集的下降曲線。圖 2 可以看到的是不管是驗證集還是測試集的曲線
都下降的很平穩，算得上是不錯的結果。 
20 
圖3. 實驗一 LSTM 神經網絡之 MSE、RMSE、r2_score 
圖 3. X 軸為顯示了實驗一的 MSE, RMSE, r2-score，Y 軸為其數值。我
們可以看到實驗一在 MSE, RMSE, r2-score 也取得了不錯的成績。 
圖4. 實驗一 LSTM 神經網絡於測試集上測試之結果 
圖 4.為實驗一的預測結果圖。X 軸為測試集的日期時間
(2019/12/30~2020/12/31，以天數算) Y 軸為指數(用 Python 標準化處理的
數值)，紅色線為實際的加權股價報酬指數的走勢，黑色線為實驗一預測
的結果。圖 4 也顯示了加權股價報酬指數的預測也可以看到十分的接
近，但在第 100 天到第 150 天出現了反轉。 
21 
實驗二、LSTM Units 使用兩層，一層 256 個神經元、一層 128 個神
經元，於第 149 回訓練時提前終止。 
圖5. 實驗二 LSTM 神經網絡之驗證集損失值及測試集損失值 
圖 5. X 軸是實驗二跑的回數，Y 軸為 loss 值，分別顯示了驗證集
(跟測試集的下降曲線。如圖 5 所示在本次的實驗結果中驗證集跟測試集
分別在 40 回跟 100 回的時候產生了較大的波動，這說明選擇這組參數
對於預測結果是較差的。 
圖6. 實驗二 LSTM 神經網絡之 MSE、RMSE、r2_score 
22 
