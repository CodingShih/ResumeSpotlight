Ross  B。  Girshick[30]提出骨幹網路。同時在 2014 年，網路模型方向誕生
了兩個非常經典的網路結構，一是牛津大學電腦視覺組的 VGG[31]，另外一個是
穀歌公司的 GoogLeNet[31][32][33][34]。VGG 使用了當時最流行的深度學習框架
Caffe[36]，並非常有先見之明的開源了其訓練好的網路模型。VGG 也作為骨幹
網路成為了之後 3-4 年的檢測演算法的主要使用骨幹網路，代表演算法便是 RBG
的 R-CNN 系列的三篇文章。隨著資料量的增大和人們對高精度的追求，骨幹網
路更深的深度成為了一個最容易想到的方向。2016 年，何愷明的殘差網路使用
short-cut 解決了深度學習中的退化問題，因為其無限深度的能力成為了近幾年物
體檢測演算法骨幹網路主要使用的演算法，經典演算法包括 R-FCN[37]，Mask R-
CNN[38]以及 YOLOv3[9]等。 
2015 年 RBG 的 Fast  R-CNN 使用 softmax 替代了 SVM，進而將特徵提取和
分類模型的訓練合二為一，算是第一個端到端的物體檢測演算法。在 R-FCN 中
使用了更為快速的投票機制替代了 Fast R-CNN[36]中的 softmax，因為 softmax 前
往往要接最少一層全連接，這也成了制約 Fast  R-CNN 速度的一個重要瓶頸。
YOLOv3 則是使用 sigmoid 啟動函數的多標籤模型增強了對覆蓋樣本的檢測能
力。2015 年 RBG 和何愷明聯手，推出了使用 RPN 替代了 Selective  Search 的
Faster  R-CNN 演算法[40]。Faster  R-CNN 因為其最高的演算法精度和在 GPU 環
境下的近即時的速度性能，也成了當時最為流行的演算法之一。 
Faster  R-CNN 系列雖然在實現上實現了端到端訓練，但是其兩步走（候選
區域提取+位置精校）的策略也被一些人詬病。2016 年，Joseph  Redmon 提出了
更為革命性的 YOLO 系列演算法[8][9][10]。不同于 R-CNN 系列分兩步走的策
略，YOLO 是單次檢測檢測的演算法，YOLO 可以看做是高精度的 RPN。其更
徹底的端到端訓練將物體檢測的速度大幅提升，在非頂端顯卡環境下也實現了即
時檢測。 
Joseph  Redmon 提出降採樣池化，無論是 Selective  Search 還是 RPN，得到
的候選區域在尺寸和比例上都是不固定的，由此輸入到網路中得到的 Feature 
Map 大小是不同的，最後展開成的特徵向量長度也不固定，在目前的開源框架下，
暫不支援變長的特徵向量作為輸入。在 SPP[40]中，作者提出了金字塔池化的方
式，通過多尺度分 bin 的形式得到長度固定的特徵向量，在 Fast  R-CNN 中將其
簡化為單尺度並命名為 ROI Pooling。Mask R-CNN 發現當 ROI Pooling 應用到語
義分割任務中會存在若干個圖元的偏移誤差，由此設計了更為精確的 ROI Align。
Faster  R-CNN 最大的特點是在 RPN 網路中引入了錨點機制，對錨點一個更好的
解釋是先驗框，即對檢測框的先驗假設。在早期階段，錨點是根據開發者的經驗
固定數值的。在 YOLOv2 中，作者在訓練集對錨點進行了 k-means 聚類，進而產
生了一組更優代表性的錨點。 
9 
在所有的檢測演算法中都普遍存在著小尺寸物體檢測困難的問題。究其原
因，是因為在深層網路中隨著語義資訊的增強，位置資訊也越來越弱，這是深度
網路的固有問題。SSD[41]率先提出使用各個階段的 Feature  Map 都參與損失函
數的計算，在 FPN 中則是通過將各個階段的 Feature Map 融合到一起的方式，融
合的方式有 FPN[42]中從小尺寸向大尺寸融合的雙線性插值上採樣演算法，也是
目前最為廣泛使用的融合方法；DSSD[43]則是通過反卷積得到不僅將小尺寸
Feature Map 上採樣，而且包含語義資訊的 Feature Map。而 YOLOv2 採用的是中
的大尺寸向小尺寸融合的 space_to_depth()演算法。而 YOLOv3 則是接合了 FPN
和錨點機制的思想，為不同深度的 Feature Map 賦予了不同比例，不同尺寸的錨
點。YOLOv2 中採用的另外一個解決方案則是在訓練過程中，不同批使用不同尺
寸的輸入圖像。系列演算法中一個非常有商業前景的方向便是通過半監督學習的
方式增加模型可處理的類別。半監督學習即是通過少量的帶標籤資料和大量的無
標籤資料，將模型的能力擴展到無標籤資料中。YOLO9000[7]通過 WordTree 融
合了 80 類的檢測資料集 COCO 和 9418 類的分類資料集 ImageNet，生成了可以
檢測 9418 類物體的模型。MaskX R-CNN[38]則是通過權值遷移函數融合了 80 類
的分割資料 COCO 和 3000 類的檢測資料集 Visual Gnome，生成了可以分割 3000
類物體的模型。 
近幾年物體檢測和語義分割的距離越來越小，雙方都在汲取對方的演算法
來獲得靈感和優化演算法。最典型的演算法便是 Mask R-CNN 中融合了分類，檢
測和分割的三任務模型。 
第四節 毫米波雷達 
所謂的毫米波是無線電波中的一段，一般認為波長為 1～10 毫米的電磁波稱
毫米波，它位於微波與遠紅外波相交疊的波長範圍，因此具有兩種波共有的特點。
所謂的毫米波雷達，就是指工作頻段在毫米波頻段的雷達，測距原理跟一般雷達
一樣，也就是把無線電波(雷達波)發出去，然後接收回波，根據收發之間的時間
差測得目標的位置資料。毫米波雷達就是這個無線電波的頻率是毫米波頻段。由
於毫米波的波長介於釐米波和光波之間，因此毫米波兼有微波制導和光電制導的
優點。同釐米波相比，毫米波設備具有體積小、品質輕和空間解析度高的特點。
毫米波穿透煙霧以及灰塵的能力強與紅外、鐳射、光學等相比更為優秀。 
10 
圖  2-4  毫米波雷達基本結構組成示意圖 
資料來源：Bocsh 
如图 2-4，毫米波雷達的基本結構是由 MMIC 晶片和天線 PCB 板組成，以
FMCW 車載雷達系統為例，主要包括：天線、收發模組、信號處理模組。前端單
片微波積體電路（MMIC），它包括多種功能電路，如低雜訊放大器（LNA）、
功率放大器、混頻器、甚至收發系統等功能。毫米波雷達天線的主流方案是微帶
陣列，即將高頻 PCB 板集成在普通的 PCB 基板上實現天線的功能，需要在較小
的集成空間中保持天線足夠的信號強度。 
圖  2-5 毫米波雷達基本工作原理示意圖 
資料來源：https://www.pianshen.com/article/73701002822/ 
如图 2-5，毫米波雷達的基本工作原理是利用高頻電路產生特定調製頻率
11 
（FMCW）的電磁波，並通過天線發送電磁波和接收從目標反射回來的電磁波，通
過發送和接收電磁波的參數來計算目標的各個參數。並且可以同時對多個目標進
行測距、測速以及方位測量；測速是根據多普勒效應，而方位測量（包括水準角
度和垂直角度）是通過天線的陣列方式來實現的。 
圖 2-6 24GHz  毫米波雷達應用頻段示意圖 
資料來源：https://www.eefocus.com/automobile-electronics/461975  
如图 2-6，24。0GHz 到 24。25GHz 的頻段是窄帶(NB)，頻寬為 250MHz，
常用於工業、科學和醫學方面。其中，24GHz 頻帶還包括一個頻寬為 5GHz 的超
寬頻(UWB)。在短程雷達中，24GHz 頻段的 NB 和 UWB 雷達已經應用於傳統的
汽車感測器上。通常 NB 雷達可以完成盲點檢測等簡單應用，但在大多數情況下
包括超短距離的情況下，由於高頻解析度的需求，需要使用 UWB 雷達。但是由
於歐洲電信標準化協會(ETSI)和聯邦通信委員會(FCC)制定的頻譜規則和標準，
UWB 頻段將很快被逐步淘汰。2022 年 1 月 1 日以後，UWB 頻段將無法在歐洲
和美國使用，只有窄帶 ISM 頻段可以長期使用。 
圖  2-7 77GHz  毫米波雷達應用頻段示意圖 
資料來源：https://www.eefocus.com/automobile-electronics/461975 
如图 2-7，  76-77GHz 頻段可用於遠端車載雷達，並且該頻段有等效同性各
向輻射功率(EIRP)的優勢，可用於前端遠端雷達。77-81GHz 短程雷達(SRR)頻段
是新加入的頻段；這個頻段最近在全球監管和行業採用情況方面都獲得了顯著的
12 
吸引力。該頻段可提供高達 4  GHz 的寬掃描頻寬，非常適合需要高範圍解析度
(HRR)的應用。 
表 2-1 各頻段毫米波雷達對比 
24GHz(24~24.25GHz)  77GHz(76~77GHz)  79GHz(77~81GHz) 
探測距離 
探測角度 
頻寬 
體積 
成本 
解析度 
頻段開放國家
數 
0.2~50m 
60° 
250MHz 
*1 
80 美元 
60cm 
>150 
10~250m 
0.15~70m 
30° 
1GHz 
*1/3 
120° 
4GHz 
*1/3 
200 美元 
200 美元 
18cm 
約 100 
5cm 
美國、新加坡、
歐洲等國 
如表 2-1，24GHz 頻段基本能達到本研究的要求，77GHz 和 79GHz 的在體
積和解析度上對比 24GHz 的毫米波雷達更優，但是價格貴出接近一倍多，實際
的可用產品，價格可能會進一步拉大。對於本研究，24GHz 的毫米波雷達更值得
使用，也符合簡易居家安全警示系統的本意。在[15]研究中應用毫米波雷達 Yolo 
V3 實做於堆高機的安全警示系統，足見毫米波雷達用於測試物件的距離是較準
確，為在行動機具(如汽車、堆高機、小山貓等)裝備上配備毫米波雷達是可行且
有其必要性，但在居家安全系統上，單價成本是考慮的重要因素，故本研究暫不
考慮毫米波雷達的裝備。 
熊丁丁在多通道毫米波雷達人體檢測定位方法研究[4]中提出多通道毫米波
雷達可獲取人體目標位置、速度以及個數等資訊，在智慧家居、智慧交通、無人
監護等領域具有廣闊的應用前景和價值。本文圍繞人體微動參數估計、走動人體
檢測、走動人體即時定位等問題開展研究，具體工作如下：  1。針對人體微動參
數估計問題，建立了微動人體的回波模型，提出了基於多通道互相關熵的微動參
數估計演算法。該演算法首先對單個通道的回波信號進行自相關熵計算處理;然
後，對上述的自相關熵矩陣兩兩互相關處理後進行算數融合，得到多通道互相關
熵矩陣;最後，對互相關熵矩陣進行成像處理，在圖像域估計出人體微動參數。相
比傳統的傅裡葉分析演算法和自相關熵演算法，該演算法能夠有效地提高微動目
標成像的信噪比，模擬結果驗證了該演算法性能。2。針對人體走動檢測問題，
建立了運動人體回波模型，改進了基於距離-多普勒二維圖像域的參數估計方法，
通過針對性距離-速度解耦合策略，如：單調頻解距離-速度耦合(慢速走動人體)
和三角調頻解距離-速度耦合(快速人體走動)，提高距離和速度參數估計精度，並
進行了理論分析與模擬驗證;分析基於 CA-CFAR 的目標檢測演算法、以及檢測
13 
後擴展目標凝聚演算法性能，並進行了模擬與實測資料驗證。3。針對人體走動
即時定位問題，研究了基於相位比較的人體走動目標定位演算法。該方法提取不
同通道的目標相位資訊，計算相鄰通道間的相位資訊差值，並將其換算成目標所
處座標的角度資訊。結合目標測距方法，計算出目標的座標資訊，實現目標的定
位。相比時差定位方法和 DOA 估計演算法，該方法原理簡單、定位精度高，能
夠實現即時定位，適用於小型天線陣列，易於工程實踐。本文針對多通道毫米波
雷達實際應用場景中出現的問題，結合模擬和實測實驗，對人體微動參數估計、
人體走動檢測、人體走動即時定位等問題展開相關研究，為後續的運動人體跟蹤
技術相關研究打下了堅實的基礎。 
徐朝陽[5]在毫米波雷達運動人體目標建模與特徵提取中提出，由於人體目
標運動狀態複雜，散射特性多變，並且探測環境存在強地雜波幹擾，所以人體運
動狀態分類一直是雷達領域的難題之一。本文圍繞運動人體目標的探測機理展開，
重點研究了步行運動狀態下的行人回波模型、運動特徵提取方式、運動狀態分類、
實測資料處理等關鍵技術。首先根據 Boulic 模型建立了簡化的人體運動模型，將
人體的行走過程轉換為剛體平移與旋轉運動的組合，將身體部件轉換為橢圓剛體。
建立了 LFMCW 雷達人體運動回波模型。通過對比模型資料與實測資料的時頻
圖，驗證了模型的正確性。其次，對於傳統時頻分析方式時頻聚焦性差的問題，
本文結合多重同步壓縮演算法，通過時頻譜的頻率維度進行壓縮，實現了人體回
波微多普勒的“精細刻畫”。Rényi 熵作為時頻譜能量聚焦性的評判準則[5]，並
將其作為多重同步壓縮門限判定的標準。並且，針對 LFMCW 雷達距離像存在擴
散的問題，設計了基於時頻譜的擴散像檢測演算法，將人體目標的微多普勒資訊
充分利用。利用圖像邊緣檢測的方式對人體時頻譜進行了特徵提取處理，並通過
SVM 分類器實現運動狀態分類。最後依託搭建的毫米波實驗平臺，獲取了人體
運動的實測資料，驗證了演算法的可行性。由[5]文可知，可以通過毫米波雷達檢
測人體位置。可以通過毫米波雷達來確定是否有物體經過，並且準確率高。但只
用於居家安全檢視，測試距離用，太過奢華，可用影像處理技術解決，居於成本
考量，因此本研究不考慮用毫米波雷達，但若經費許可，加入毫米波雷達，可提
高系統對人物距離判斷的準確度。 
第五節 微處理機系統 
        王志宇(Chih-Yu  Wang)  提出基於深度學習之嵌入式即時行人偵測及追蹤系
統[12]，文中提到在科技進步，機器人將會在居家照護、無人商店和監視監控等
領域越來越多的出現。所以一項重要的技術被提出也就是基於視覺的行人跟蹤，
它可以讓機器人跟隨人們，無論人的行動範圍。該文所提出的行人跟蹤方法是運
行在 Raspberry Pi 3 上，它僅具備 1.2GHz  的 ARM CPU 和 1GB RAM，但是卻可
以達到實時且穩定的運行，並且所需的硬體成本僅有 35 美元，這使得物聯網的
14 
應用能更加廣泛的推廣和實施。作為最基礎的項目，行人偵測的準確性和速度對
於可靠的跟蹤系統極為重要。但是，常用的深度學習物件偵測方法，例如 Faster 
R-CNN 和 YOLO 等方法，需要設備有大量的儲存空間和較為強大的算力支援，
需要使用高階的 CPU 或 GPU 才能達到實時(30fps)運行，但像 Raspberry  Pi  3 這
樣僅具備低階 CPU 或 FPGA 的嵌入式平臺上要運行仍然有較大的困難。因此，
該文通過優化模型架構，並且使用各種訓練的技巧，從而獲得了可靠並且輕量化
的人體偵測模型 Brisk-YOLO。並且，此該訓練模型與其他物件偵測模型相比在
相同的公開資料集上，在保證偵測行人的準確率下，將 Tiny-YOLO 偵測速度提
高了 55 倍，從而在 Raspberry Pi 3 上達到 22FPS。並且，為了進一步減少算力，
該模型並不會逐幀演算，只有當模型出現較大誤差或目標丟失時才讓模型進行修
正。作者挑選了速度快的目標跟蹤器(Object  Tracking)和行人再識別(Person  Re-
identification)方法，從而確保該系統長時間的穩定運作。通過在 BoBoT 數據集上
實驗表明，該系統在現實的偵測行人環境中，相較於其他實時跟蹤演算法，該作
者提出的模型在速度和準確率都更為優秀。該文[10]提出使用樹莓派運行 YOLO
來偵測行人，啟發使用 Jetson Nano 運行 YOLO 提供實踐思路，由於 Jetson Nano
性能並不強，使用原版 YOLO 偵測時幀數過低。可能也需要通過剪枝等方式，
強化 YOLO 的運作。 
        王靜波的基於嵌入式的行人檢測跟蹤研究與實現[13]，該論文在行人檢測方
面，以 YOLO-v3 演算法為基礎，對該演算法的檢測原理和網路訓練過程進行詳
細研究，並提出基於自我調整空間特徵金字塔融合的模型優化方法，加入一種可
提升感受野的 RFB 模組，有效融合深層次特徵，提升行人檢測模型識別率。然
後整合公開資料集 voc、coco、sysu 和 prw 的行人圖片，構建行人資料集，並使
用 pytorch 框架完成資料訓練，最終模型測試集 mAP 達到 78。96，通過網路選
取行人圖片測試效果良好，證明模型泛化能力優良。在行人多目標跟蹤方面，採
用的多目標跟蹤的 Deep sort 演算法，分析 Deep sort 的具體演算法原理，並提出
一些優化的策略，最後基於前面得到的 YOLO-v3 優化模型，把檢測和跟蹤兩者
結合，完成一體化設計，並在 MOT16 資料集和實際行車記錄儀上測試，性能良
好，達到精度高、即時性滿足需求的目的。根據該文提出的基於 YOLOv3 行人
檢測跟蹤優化演算法，做出了基於嵌入式板卡 Jetson  nano 的具體實現。首先闡
述了選取 NVIDIA Jetson nano 作為本系統的運行平臺的原因，nano 作為 NVIDIA
自家嵌入式產品，具備 cuda 核心可方便移植 GPU 演算法，加快研發效率。然後
基於 TensorRT 加速特點，對本文所用的行人檢測模型進行優化加速，提出一些
模型剪枝方法，並在此基礎上做模型剪枝。對於當前構建資料集，對 YOLOv3 進
行模型剪枝之後，模型的參數量、模型大小減少 80%，FLOPs 降低 70%，前向推
斷的速度可以達到原來的 200%，同時可以保持 mAP 基本不變。最後採用目前成
熟方案，Pytorch 模型-ONNX-TensorRT 模型，成功實現嵌入式端的模型優化加
速。最後考慮線路的簡化行，採用用戶端多併發機制 ImageZMQ 無線傳輸視頻
15 
的和伺服器端接收的方式搭建行人監測系統，並進行測試，而且本系統可同時處
理多路視頻，可通過調節幀尺寸大小，加快處理速度。處理速度大約為 20fps，
較原始模型提高大約 2 倍左右，證明系統穩定可靠，可用於即時檢測跟蹤行人和
行人分析統計等。 
        李鬱晨(Yu-Chen  Lee)在晶圓圖缺陷分類與嵌入式系統實現[14]提出在半導
體工業中，晶圓測試扮演不可或缺的一環，於生產的最後階段會進行不同電性的
測試以確保產品的功能性，而測試結果再結合晶圓形狀所產生的圖形稱作晶圓圖
(Wafer Map)，可以決定是否進行後續封裝等動作。然而，判斷產生的缺陷(defect)
大多仰賴人工來執行，不僅耗費時間且需要經驗豐富之工程師。[14]別對網路上
公開資料集 WM-811K，以及公司合作所建立的資料集，進行晶圓圖缺陷分類。
研究可分成兩個部分，一是神經網路的訓練，二是嵌入式系統上實現。神經網路
部分，採用深度可分離卷積(depth separable convolution)的結構為基礎，設計出具
有低參數量之神經網路，針對 WM-811K 中 8 類不同缺陷進行分類，最終可達
97。01%準確度。在自行建立的資料集中，一共蒐集了 16388 張晶圓圖，定義 21
個缺陷類別，並對其進行擴增與分類，最終達 87。4%準確度。系統方面，建立
的資料使用 MongoDB 資料庫進行管理，放置於嵌入式板 Jetson Nano，可連結遠
端 server 進行訓練，回傳模型於嵌入式板執行推理(inference)。此系統可以令使
用者持續更新資料集，並對原模型進行優化，對於現今各公司晶圓缺陷定義不同，
以及標注資料緩慢等問題，提供初步解決方案。 
        基於上述相關理論，使用毫米波雷達可以判斷是否有物體出現在居家環境
一定距離範圍，YOLO 辨識該物體是否是人類，並且判斷是否有可疑性，最終
記錄相關影像片段，並警告相關人員，以達到監控居家環境安全之目的。 
16 
第三章 研究方法 
第一節 研究流程 
本研究希望通過智慧影像辨識和毫米波雷達感測器，設計一套可以安裝在
居家環境中的簡易居家安全警示系統。將深度學習網路建置到嵌入式系統平
臺，使該平臺能自動偵測移動物體並辨識，根據偵測結果發出警示等，避免出
現竊盜事件，以及配合相關人員快速偵破竊盜案件。 
現如今人工智慧技術快速發展，並在圖像處理技術的推波助瀾下，在影像
辨識的應用上，有更多的發展和進步。人臉辨識、行為辨識等都日趨成熟。本
論文將在居家環境中配置攝像頭，用來搜集居家環境的周圍影像。通過這鏡頭
所搜集的影像作為輸入資料，判斷居家環境周圍是否有可疑人員經過，及時提
醒相關人員並且儲存相關片段，完成一個人工智慧居家安全警示系統。 
本研究目標為偵測居家環境周圍是否有可疑人員之問題，此問題屬於影像
偵測中的物體偵測，不須加上毫米波雷達的資料就可以達成這一目標，因此計
劃結合電腦視覺和人工智慧來達成。圖 3-1 為此次的實驗流程圖，將攝像頭架
設 Jetson Nano 機殼上，並將整個設備架設與居家的圍墻上，將攝像頭對準所要
偵測的區域。系統啟動後，攝像頭會一直處於偵測狀態，並且通過影像處理判
斷是否有人出現，是否靠近居家圍墻來啟動人工智慧圖像分類演算法進一步偵
測。通過調整人工智慧影像作圖像分類判斷，使其判別影像中人是否有佩戴口
罩、墨鏡、帽子和左顧右盼等行為異常的現象。 
結合上述攝像頭搜集之數據和物體偵測結果，整合輸出人體判斷結果和裝
扮異常判斷結果，後續判斷是否超過安全閾值，若超過安全閾值，則本系統會向
相關人員提出警示，並錄影相關片段，反之，則不提出警示。 
17 
圖 3-1  研究流程圖 
18 
第二節 軟硬體需求 
一、前饋式類神經網路 
首先進行前饋式類神經網路(Feedforward Neural Network，簡稱 FNN)  是參
數從輸入層向輸出層單向傳播，有別於循環神經網路。圖 3-2 是 FNN 的網路架
構。輸入端影像是解析度為 28*28，有 784 個書如神經元，輸出端是 5 大類影
像分類結果 
圖 3-2  前饋式神經網路架構圖 
二、多層感知機類神經網路架構 
多層感知機類神經網路架構(Multilayer Perceptron，簡稱 MLP)  是一種正向
結構的人工神經網路，由一組輸入向量映射到一組輸出向量。可以將 MLP 看作
是由多個節點層組成的有向圖，每個節點層都連接到下一層。除了輸入節點
外，每個節點都是具有非線性起始函數的神經元(或處理單元)。MLP 使用權值
存儲資料，演算法在訓練過程中調整權值，減少偏差，即實際值與預測值之間
的誤差越小越好。它的主要優點是能夠快速解決複雜問題。多層感知的基本結
構由三層組成(圖 3-3)：第一輸入層，中間隱藏層和最後輸出層，輸入元素和權
重的乘積被饋入具有神經元偏差的求和節點，主要優勢在於其快速解決複雜問
題的能力 
19 
三、卷積神經網路架構 
圖  3-3    MLP 網路架構 
卷積神經網路(Convolutional Neural Network)簡稱 CNN，卷積神經網路由
一個或多個卷積層和頂端的全連通層（對應經典的神經網路）組成，同時也包
括關聯權重和池化層（pooling layer），將二維結構影像資料輸入到卷積神經網
路運算處理，與其他深度學習結構相比，卷積神經網路在圖像和語音辨識方面
能夠獲得更好的結果(圖 3-4)。 
圖  3-4    CNN 網路架構 
20 
四、 YOLOv4 架構 
AlexeyAB  繼承了  YOLO  系列的思想和理念，在  YOLOv3  的基礎上不斷進
行改進和開發，於 2020 年 4 月發佈發佈  YOLOv4，並得到了原作者  Joseph 
Redmon  的承認。在目標檢測領域引起廣泛的討論。YOLOv4  可以使用傳統的 
GPU  進行訓練和測試，並能夠獲得即時的，高精度的檢測結果。YOLOv4  在與 
EfficientDet  性能相當的情況下，推理速度比其快兩倍。相比  YOLOv3  的  AP  和 
FPS  分別提高了  10%  和  12%。Yolov4 的五個基本組件。首先，CBM 是 YOLOV4
網路架構中最小的元件，由 CONV  +  BN  +  MISH 啟動功能組成。CBL 由
Conv+Bn+Leaky_relu 引導函數組成。其次，RES Unit 借鑒了 RESNET 的殘差結
構，使網路構建更加深入。然後，參照 CSPNET 的網路結構，CSPX 由卷積層和
X RES Unint 模組 Concat 組成。最後，採用 1×1，  5× 5，9 × 9，13 ×13 的最大池
化進行 SPP 多尺度融合(圖 3-5)。 
圖  3-5 YOLOv4 架構圖 
與 YOLOV3 相比，由於增加了 CSP 結構和 PAN 結構，YOLOV4 的總體架構與
YOLOV3 相同，但在各個子結構上採用了各種新的演算法思想。 
五、微處理主機板系統 
        本研究希望在訓練完模型後，進一步將模型建置到 Jetson  Nano 系統图 3-6
平臺上，增加此系統的便利性和可操作性。本研究計劃採用 Jetson Nano，由表 3-
1 可知 Jetson Nano 體積小巧，價格低廉，並且相比於其他更加先進的型號，其
功耗更加低，最大功耗僅 10W。本研究計劃將影像辨識模型建置於 Jetson  Nano
上，並實現實時的簡易居家安全警示系統。表 3-2 為整套系統預計價格。 
21 
表  3-1 Jetson 家族各個平臺對比 
圖  3-6 Jetson Nano 設備圖 
Xavier NX 
(15W) 
AGX Xavier 
Jetson Nano 
(4G) 
Jetson Nano 
(2G) 
CPU 
GPU 
Accelerators 
記憶體 
儲存空間 
USB 
4x/6x Carmel 
@ 1.4GHz 
or 
2x Carmel 
@ 1.9GHz 
Volta ，   384 
Cores 
@ 1100MHz 
2x NVDLA 
8GB 
LPDDR4X ， 
128-bit bus 
(51。2 GB/sec) 
16GB eMMC 
8x Carmel 
@ 2.26GHz 
4x Cortex-A57 
@ 1.43GHz 
4x Cortex-A57 
@ 1.43GHz 
Volta ，   512 
Cores 
@ 1377MHz 
2x NVDLA 
Maxwell ， 
128 Cores 
@ 920MHz 
N/A 
Maxwell ， 
128 Cores 
@ 920MHz 
N/A 
16GB 
LPDDR4X ， 
256-bit bus 
(137 GB/sec) 
32GB eMMC 
4GB 
LPDDR4 ， 
64-bit bus 
(25。6 GB/sec) 
16GB eMMC  microSD 
2GB 
LPDDR4 ， 
64-bit bus 
(25。6 GB/sec) 
4x  USB-A  3.1 
Gen 2 
2x USB-C 3.1 
1x USB-A 3.0 
4x USB-A 3.0  1x USB-A 3.0 
2x USB-A 2.0 
1x 
USB-C 
(Power) 
N/A 
N/A 
x 
45mm x 70mm  45mm x 70mm 
10W 
$99 
10W 
$59 
AI Perf. 
21 TOPS 
32 TOPS 
尺寸 
TDP 
價格 
45mm x 70mm  100mm 
87mm 
30W 
15W 
$399 
$699 
22 
表 3-2  使用 Jetson Nano 整套裝備價格表 
設備規格 
數量 
設備名稱 
嵌入式系統 
攝像頭 
機殼 
NVIDIA Jetson 
Nano 
IMX219 800M 
pixel 120° 
Jetson Nano 專用
機殼 
WIFI 晶片 
Jetson Nano 8264 
毫米波雷達 
Continental ARS 
AC wifi 
408 Long Range 
Radar Sensor 
六、資料集 
1 
2 
1 
1 
1 
價格 
3500 
1000 
300 
350 
17000~23800 
      圖片都來源於網路無版權的公開圖片。訓練與驗證資料圖片分為五類，戴口
罩圖片、戴墨鏡圖片、戴帽子圖片、左顧右盼圖片、未佩戴任何飾品並正面朝
向圖片，共計一萬張。戴口罩圖片部分，訓練用圖片共計一千八百張，驗證用
圖片兩百張。戴墨鏡圖片部分，訓練用圖片共計一千八百張，驗證用圖片兩百
張。戴帽子圖片部分，訓練用圖片共計一千八百張，驗證用圖片兩百張。左顧
右盼圖片部分，訓練用圖片共計一千八百張，驗證用圖片兩百張。未佩戴任何
飾品並正面朝向圖片部分，訓練用圖片共計一千八百張，驗證用圖片兩百張。 
  測試資料部分，共搜集與上述訓練資料和驗證資料不同的圖片一千張。其
中，戴口罩圖片兩百張，戴帽子圖片兩百張，戴墨鏡圖片兩百張，左顧右盼圖
片兩百張，未佩戴任何飾品並正面朝向之圖片兩百張，未佩戴飾品並正面朝向
之圖片在 YOLO 測試部分結果不計入統計。 
圖  3-7 圖片範例 
如图 3-7，依次為未佩戴任何飾品、帽子圖片、口罩圖片、墨鏡圖片和左
顧右盼的圖片。未佩戴任何飾品圖片檔夾命名為 none，口罩圖片檔夾命名為
mask，帽子圖片檔夾命名為 hat，墨鏡圖片命名為 sgs，左顧右盼圖片檔命名為
la，測試圖片檔夾後面加-test。 
23 
第三節 演算法 
本節將依序介紹本研究所提的三種網路架構和 YOLO 的演算法。構建神經
網路需要配置模型的層，然後編譯模型。  在許多情況下，這可以簡化為簡單地
將層堆疊在一起，使用的激活函數有 ReLu 和 softmax(圖 3-8)，Sigmoid 函數實
際上就是把資料映射到一個(0,1)的空間上，也就是說，Sigmoid 函數如果用來分
類的話，只能進行二  分類(，而這裡的 softmax 函數可以看做是 Sigmoid 函數的
一般化，可以進行多分類，即 softmax  函數，可以將 Y 轉為機率值，且所有類
別的機率總和等於 1，就適合多分類，最大值就代表可能性最大(如圖 3-9)。 
圖 3-8  激活函數  sigmoid  和 Relu 
圖 3-9  激活函數 softmax 
一、  FNN 演算法 
演算法  FNN 
輸入: 10000 張  2828  圖像 
輸出:  分類成五大類的準確度與損失率 
處理: 
1.  下載 10000 張影像資料 
2.  2828 圖像資料前處理(包括 2 維轉 1 維和資料正規化，將所有資料
轉成 0 到 1 之間數值) 
3.  建立類神經網路 FNN 模型 
24 
